# Level 5

Streams: Reading, writing, piping



# Streams



Streams are a universal interface that can apply to many instances, allowing code reuse.


Streams treat data one chunk at a time, and this are memory-efficient.



# Examples of streams

* HTTP request (write stream)
* HTTP response (read stream)
* TCP connection (duplex stream)
* File read stream
* File write stream
* Parser (transform stream)
* ...



# Read stream

```js
var fs = require('fs');
var stream = fs.createReadStream('/path/to/file');
```


## Setting encoding

```js
stream.setEncoding('utf8');
```


## Push stream

```js
stream.on('data', function(data) {
  console.log('some data:', data)
});
```

(`data` is `Buffer` or string, depending on whether encoding is set.)


## Pull stream

```js
stream.on('readable', function() {
  var buffer;
  while(buffer = stream.read()) {
    console.log('some data:', buffer);
  }
});
```


## Object streams

```js
stream.on('data', function(obj) {
  console.log('not a buffer or a string:', obj);
});
```



## Exercise 5.1

1. Download [code/05/registry.json.gz](https://github.com/pgte/node-workshop/raw/master/code/05/registry.json.gz)
1. Unzip it
1. Create a file read stream
1. Using push mode (`.on('data')`), print all the data
1. Set encoding to `utf8` 
1. Again, using push mode, print all the data
1. Print all the data using pull mode `.on('readable')`



# Write Stream


```js
var buffer = new Buffer([1,2,3,4,5]);

stream.write(buffer);
stream.write('some string');
stream.write('some string', 'utf8');
stream.write('some string', 'utf8', function(err) {
  console.log('wrote');
});

stream.end();
```


## Example

```js
var fs = require('fs');
var stream = fs.createWriteStream('/path/to/file');

stream.write('some content\n');
stream.write('some more content\n');
stream.end('here is a final piece');
```



# Pipe

Pipe a read stream into a write stream.

```js
read.pipe(write);
```


## Example

Copying a file

```js
var fs = require('fs');

var from = fs.createReadStream('source.txt');
var to = fs.createWriteStream('target.txt');

from.pipe(to);
```



![Duplex Streams](images/duplex_streams.png)

A stream that is both readable and writable.


## Duplex stream

Example: a TCP connection.

```js
var net = require('net');
var c = net.connect(8000, 'my.host.com');

c.setEncoding('utf8');
c.on('data', function(data) {
  c.write(data.toUpperCase());
});
```



# Transform Stream

A stream that is both readable and writable.

Example: unzip



## Chain pipes

```js
source.pipe(transform).pipe(target);
```



## Exercise 5.2

1. Create an unzip transform stream
2. Create a file read stream for `code/05/registry.json.gz`
3. Pipe from that stream into the unzip stream
4. Pipe the unzip stream into `process.stdout`


[one solution](code/05/unzip.js)

```js
// unzip.js
var join = require('path').join;
var fs = require('fs');
var zlib = require('zlib');

var unzip = zlib.Unzip();
var source = fs.createReadStream(join(__dirname, 'registry.json.gz'));

source.pipe(unzip).pipe(process.stdout);
```



## Split2

Splits by new-line char or other matcher

```
$ npm install split2
```



## through2

To create transform streams easily:

```js
var through2 = require('through2');

var stream = through2(function(chunk, enc, callback) {
  this.push(chunk.toString().toUpperCase());
});
```


Or, in object mode:

```js
var through2 = require('through2');

var stream = through2.obj(function(obj, enc, callback) {
  this.push({
    value: obj,
    when: new Date()
  });
});
```



## Exercise 5.3

Using the previous code, chain these streams:

* read file
* unzip
* split by line
* remove a trailing comma (",")
* parse JSON

and then print every object coming out ot the stream.


[one solution](code/05/compose.js)

```js
var join = require('path').join;
var fs = require('fs');
var zlib = require('zlib');
var split2 = require('split2');
var through2 = require('through2');

var source = fs.createReadStream(join(__dirname, 'registry.json.gz'));

var removeComma = through2(function(chunk, encoding, callback) {
  chunk = chunk.toString().trim();
  if (chunk[chunk.length - 1] == ',') {
    chunk = chunk.slice(0, chunk.length - 1);
  }
  this.push(chunk);
  callback();
});

var parse = through2.obj(function(chunk, encoding, callback) {
  chunk = chunk.toString();
  try {
    this.push(JSON.parse(chunk));
  } catch(err) {
    parse.emit('error', err);
  }
  callback();
});

var stream =
  source.
    pipe(zlib.createGunzip()).
    pipe(split2()).
    pipe(removeComma).
    pipe(parse)
    ;

stream.on('data', function(d) {
  console.log(d);
});
```



## Exercise 5.4

Extend the previous exercise to filter by `record.doc.maintainers` that contain the word "pedro".


[one solution](code/05/filter.js)

```js
var join = require('path').join;
var fs = require('fs');
var zlib = require('zlib');
var split2 = require('split2');
var through2 = require('through2');

var source = fs.createReadStream(join(__dirname, 'registry.json.gz'));

var removeComma = through2(function(chunk, encoding, callback) {
  chunk = chunk.toString().trim();
  if (chunk[chunk.length - 1] == ',') {
    chunk = chunk.slice(0, chunk.length - 1);
  }
  this.push(chunk);
  callback();
});

var parse = through2.obj(function(chunk, encoding, callback) {
  chunk = chunk.toString();
  try {
    this.push(JSON.parse(chunk));
  } catch(err) {
    parse.emit('error', err);
  }
  callback();
});

var filter = through2.obj(function(record, encoding, callback) {
  if (record.doc.maintainers && record.doc.maintainers.some(function(maintainer) {
    var name = maintainer = maintainer.name || maintainer;
    return maintainer && maintainer.match(/pedro/i);
  })) {
    this.push(record);
  };
  callback();
});

var stream =
  source.
    pipe(zlib.createGunzip()).
    pipe(split2()).
    pipe(removeComma).
    pipe(parse).
    pipe(filter)
    ;

stream.on('data', function(d) {
  console.log('%s (%j)', d.doc.name, d.doc.maintainers);
});
```